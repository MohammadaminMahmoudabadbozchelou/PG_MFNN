{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='-1'\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.contrib.opt import ScipyOptimizerInterface\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import random\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def hyper_initial(self, layers):\n",
    "        L = len(layers)\n",
    "        W = []\n",
    "        b = []\n",
    "        for l in range(1, L):\n",
    "            in_dim = layers[l-1]\n",
    "            out_dim = layers[l]\n",
    "            std = np.sqrt(2/(in_dim + out_dim))\n",
    "            weight = tf.Variable(tf.random_normal(shape=[in_dim, out_dim], stddev=std))\n",
    "            bias = tf.Variable(tf.zeros(shape=[1, out_dim]))\n",
    "            W.append(weight)\n",
    "            b.append(bias)\n",
    "\n",
    "        return W, b\n",
    "\n",
    "    def fnn(self, W, b, X, Xmin, Xmax):\n",
    "        A = 2.0*(X - Xmin)/(Xmax - Xmin) - 1.0\n",
    "        L = len(W)\n",
    "        for i in range(L-1):\n",
    "            A = tf.tanh(tf.add(tf.matmul(A, W[i]), b[i]))\n",
    "        Y = tf.add(tf.matmul(A, W[-1]), b[-1])\n",
    "        \n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "def callback(loss_,loss_lf_,loss_hf_):\n",
    "    global n\n",
    "    n += 1\n",
    "    if n%1000 == 0:\n",
    "        print('n: %d, loss: %.3e, loss_lf: %.3e, loss_hf: %.3e'%(n, loss_, loss_lf_, loss_hf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "YH1_train = np.genfromtxt('Vis_Train_H.txt')\n",
    "XH1_train = np.genfromtxt('StT_Train_H.txt')\n",
    "XH2_train = np.genfromtxt('Shr_Train_H.txt')\n",
    "XH3_train = np.genfromtxt('Age_Train_H.txt')\n",
    "\n",
    "YH1_train = YH1_train.reshape((-1,1))\n",
    "XH1_train = XH1_train.reshape((-1,1))\n",
    "XH2_train = XH2_train.reshape((-1,1))\n",
    "XH3_train = XH3_train.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "YH1_test = np.genfromtxt('Vis_Test_H.txt')\n",
    "XH1_test = np.genfromtxt('StT_Test_H.txt')\n",
    "XH2_test = np.genfromtxt('Shr_Test_H.txt')\n",
    "XH3_test = np.genfromtxt('Age_Test_H.txt')\n",
    "\n",
    "YH1_test = YH1_test.reshape((-1,1))\n",
    "XH1_test = XH1_test.reshape((-1,1))\n",
    "XH2_test = XH2_test.reshape((-1,1))\n",
    "XH3_test = XH3_test.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "YL1_train = np.genfromtxt('Vis_L.txt')\n",
    "XL1_train = np.genfromtxt('StT_L.txt')\n",
    "XL2_train = np.genfromtxt('Shr_L.txt')\n",
    "XL3_train = np.genfromtxt('Age_L.txt')\n",
    "\n",
    "y_lf = ((np.random.normal(1,0.025,len(YL1_train))) * YL1_train).reshape(1,-1).T\n",
    "x_lf = ((np.random.normal(1,0.025,len(XL1_train))) * XL1_train).reshape(1,-1).T\n",
    "t_lf = ((np.random.normal(1,0.025,len(XL2_train))) * XL2_train).reshape(1,-1).T\n",
    "w_lf = ((np.random.normal(1,0.025,len(XL3_train))) * XL2_train).reshape(1,-1).T\n",
    "\n",
    "X_lf = np.hstack((x_lf,t_lf,w_lf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hf = YH1_train.reshape(1,-1).T\n",
    "x_hf = XH1_train.reshape(1,-1).T\n",
    "t_hf = XH2_train.reshape(1,-1).T\n",
    "w_hf = XH3_train.reshape(1,-1).T\n",
    "\n",
    "X_hf = np.hstack((x_hf,t_hf,w_hf))\n",
    "\n",
    "Xmin = X_hf.min(0)\n",
    "Xmax = X_hf.max(0)\n",
    "Ymin = y_hf.min(0)\n",
    "Ymax = y_hf.max(0)\n",
    "\n",
    "Xhmin = np.hstack((Xmin, Ymin))\n",
    "Xhmax = np.hstack((Xmax, Ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "layers_lf = [D] + 2*[20] + [1]\n",
    "layers_hf_nl = [D+1] + 2*[10] + [1]\n",
    "layers_hf_l = [D+1] + [1]\n",
    "\n",
    "x_train_lf = tf.placeholder(shape=[None, D], dtype=tf.float32)\n",
    "y_train_lf = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "x_train_hf = tf.placeholder(shape=[None, D], dtype=tf.float32)\n",
    "y_train_hf = tf.placeholder(shape=[None, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN()\n",
    "W_lf, b_lf = model.hyper_initial(layers_lf)\n",
    "W_hf_nl, b_hf_nl = model.hyper_initial(layers_hf_nl)\n",
    "W_hf_l, b_hf_l = model.hyper_initial(layers_hf_l)\n",
    "\n",
    "y_pred_lf = model.fnn(W_lf, b_lf, x_train_lf, Xmin, Xmax)\n",
    "#low-fidelity values to serve as the input for the high-fidelity NN\n",
    "y_pred_lf_hf = model.fnn(W_lf, b_lf, x_train_hf, Xmin, Xmax)\n",
    "#nonlinear part with two inputs (x_H, y_l(x_H))\n",
    "y_pred_hf_nl = model.fnn(W_hf_nl, b_hf_nl, tf.concat([x_train_hf, y_pred_lf_hf], 1), Xhmin, Xhmax)\n",
    "#linear part with two inputs (x_H, y_l(x_H))\n",
    "y_pred_hf_l = model.fnn(W_hf_l, b_hf_l, tf.concat([x_train_hf, y_pred_lf_hf], 1), Xhmin, Xhmax)\n",
    "y_pred_hf = y_pred_hf_l + y_pred_hf_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_l2 = tf.add_n([tf.nn.l2_loss(w_) for w_ in W_hf_nl])\n",
    "loss_lf = tf.reduce_mean((tf.square(y_pred_lf - y_train_lf)))\n",
    "loss_hf =  tf.reduce_mean((tf.square(y_pred_hf - y_train_hf)))\n",
    "loss = loss_lf + loss_hf + loss_l2\n",
    "train_adam = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "train_lbfgs = ScipyOptimizerInterface(loss,\n",
    "                                      method = 'L-BFGS-B', \n",
    "                                      options={'maxiter': 50000,\n",
    "                                               'ftol': 1.0*np.finfo(float).eps\n",
    "                                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the cell below just only for model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = saver.restore(sess, 'MPINNModel/MPINN_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam Optimizer\n",
      "n: 1000, loss: 3.471e-02, loss_lf: 4.813e-03, loss_hf: 7.290e-03\n",
      "n: 2000, loss: 9.328e-03, loss_lf: 4.122e-03, loss_hf: 5.203e-03\n",
      "LBFG-S Optimizer\n",
      "n: 3000, loss: 4.236e-03, loss_lf: 3.173e-03, loss_hf: 1.063e-03\n",
      "n: 4000, loss: 4.013e-03, loss_lf: 3.127e-03, loss_hf: 8.861e-04\n",
      "n: 5000, loss: 3.752e-03, loss_lf: 3.159e-03, loss_hf: 5.935e-04\n",
      "n: 6000, loss: 3.598e-03, loss_lf: 3.170e-03, loss_hf: 4.274e-04\n",
      "n: 7000, loss: 3.498e-03, loss_lf: 3.177e-03, loss_hf: 3.210e-04\n",
      "n: 8000, loss: 3.449e-03, loss_lf: 3.169e-03, loss_hf: 2.796e-04\n",
      "n: 9000, loss: 3.387e-03, loss_lf: 3.168e-03, loss_hf: 2.198e-04\n",
      "n: 10000, loss: 3.355e-03, loss_lf: 3.168e-03, loss_hf: 1.875e-04\n",
      "n: 11000, loss: 3.327e-03, loss_lf: 3.157e-03, loss_hf: 1.696e-04\n",
      "n: 12000, loss: 3.300e-03, loss_lf: 3.157e-03, loss_hf: 1.429e-04\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.003299\n",
      "  Number of iterations: 9339\n",
      "  Number of functions evaluations: 10134\n",
      "Adam Optimizer\n",
      "n: 13000, loss: 3.299e-03, loss_lf: 3.155e-03, loss_hf: 1.440e-04\n",
      "n: 14000, loss: 3.299e-03, loss_lf: 3.156e-03, loss_hf: 1.426e-04\n",
      "n: 15000, loss: 3.298e-03, loss_lf: 3.156e-03, loss_hf: 1.419e-04\n",
      "n: 16000, loss: 3.298e-03, loss_lf: 3.156e-03, loss_hf: 1.421e-04\n"
     ]
    }
   ],
   "source": [
    "nmax1 = 2000\n",
    "nmax2 = 20000\n",
    "loss_c = 1.0e-6\n",
    "loss_ = 1.0\n",
    "train_dict = {x_train_lf: X_lf, y_train_lf: y_lf, x_train_hf: X_hf, y_train_hf: y_hf}\n",
    "print('Adam Optimizer')\n",
    "while n < nmax1 and loss_ > loss_c:\n",
    "    n += 1\n",
    "    loss_, _, loss_lf_, loss_hf_ = sess.run([loss, train_adam, loss_lf, loss_hf], feed_dict=train_dict)\n",
    "    if n%1000 == 0:\n",
    "        print('n: %d, loss: %.3e, loss_lf: %.3e, loss_hf: %.3e'%(n, loss_, loss_lf_, loss_hf_))\n",
    "        saved_path = saver.save(sess, 'MPINNModel/MPINN_Model')\n",
    "\n",
    "print('LBFG-S Optimizer')\n",
    "train_lbfgs.minimize(sess, feed_dict=train_dict, fetches=[loss, loss_lf, loss_hf], loss_callback=callback)\n",
    "\n",
    "print('Adam Optimizer')\n",
    "while n < nmax2 and loss_ > loss_c:\n",
    "    n += 1\n",
    "    loss_, _, loss_lf_, loss_hf_ = sess.run([loss, train_adam, loss_lf, loss_hf], feed_dict=train_dict)\n",
    "    if n%1000 == 0:\n",
    "        print('n: %d, loss: %.3e, loss_lf: %.3e, loss_hf: %.3e'%(n, loss_, loss_lf_, loss_hf_))\n",
    "        saved_path = saver.save(sess, 'MPINNModel/MPINN_Model')\n",
    "\n",
    "print('LBFG-S Optimizer')\n",
    "train_lbfgs.minimize(sess, feed_dict=train_dict, fetches=[loss, loss_lf, loss_hf], loss_callback=callback)\n",
    "        \n",
    "print(\"Training is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_h = XH1_test[len(XH1_test)-42:len(XH1_test)].reshape((-1, 1))\n",
    "t_test_h = XH2_test[len(XH2_test)-42:len(XH2_test)].reshape((-1, 1))\n",
    "w_test_h = XH3_test[len(XH3_test)-42:len(XH3_test)].reshape((-1, 1))\n",
    "\n",
    "X_test_h = np.hstack((x_test_h,t_test_h,w_test_h))\n",
    "\n",
    "y_hf_ref = YH1_test[len(YH1_test)-42:len(YH1_test)].reshape((-1, 1))\n",
    "y_hf_test = sess.run(y_pred_hf, feed_dict={x_train_hf: X_test_h})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Results/Y_A.txt', y_hf_ref)\n",
    "np.savetxt('Results/Y_M.txt', y_hf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0*42\n",
    "b=1*42\n",
    "\n",
    "ShR = np.power(10,XH2_test[a:b])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.rc('font', size=20)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=20)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=22)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=20)    # legend fontsize\n",
    "plt.rc('figure', titlesize=22)  # fontsize of the figure title\n",
    "\n",
    "plt.plot(ShR,np.power(10,y_hf_test[a:b]), 'bs--', linewidth=3.0)\n",
    "plt.plot(ShR,np.power(10,y_hf_ref[a:b]) , 'rd:', linewidth=3.0)\n",
    "#plt.plot(np.power(10,t_lf[401:442]),np.power(10,y_lf[401:442]) , 'rd:', linewidth=3.0)\n",
    "\n",
    "plt.xlabel('Shear Rate')\n",
    "plt.ylabel('Viscosity')\n",
    "plt.legend(['Predicted Data using MPINN','Actual Data from Experiment'])\n",
    "plt.title('Actual and Predicted Flow Curve for a Random Batch')\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.rc('font', size=20)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=20)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=22)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=20)    # legend fontsize\n",
    "plt.rc('figure', titlesize=22)  # fontsize of the figure title\n",
    "\n",
    "plt.plot(y_hf_ref,y_hf_test, 'kd', linewidth=5.0)\n",
    "plt.plot(np.linspace(-0.5, 1.5, 100),np.linspace(-0.5, 1.5, 100), 'r--', linewidth=3.0)\n",
    "plt.xlabel('Actual Data')\n",
    "plt.ylabel('Predicted Data')\n",
    "plt.legend(['Actual Regression','Perfect Regression'])\n",
    "plt.title('Regression Between Actual and Predicted Data')\n",
    "\n",
    "plt.grid(color='g', linestyle=':', linewidth=1)\n",
    "\n",
    "#plt.xlim(-0.5, 1.5)\n",
    "#plt.ylim(-0.5, 1.5)\n",
    "\n",
    "#plt.text(-4500, 11500, 'Pearson Regression Correlation is 0.94', style='italic',bbox={'facecolor': 'blue', 'alpha': 0.1, 'pad': 5})\n",
    "\n",
    "#plt.savefig('00 Research Codes/02_Multi_Fidelity/With_Randy/FX1_linear_regression.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
